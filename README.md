Wunderbar, Belkis ğŸ‘Œ
Ich habe dein README in ein **professionelles GitHub-Layout** gebracht â€“ klar strukturiert, mit Badges, Markdown-Formatierung, eleganten Ãœberschriften, passenden Icons und Textfluss wie bei offiziellen Projekten auf Hugging Face oder OpenAI.

Es erklÃ¤rt dein Projekt komplett â€” **ohne zu verraten, wie man deine Daten wiederverwenden kann** (nur allgemeine Funktionsbeschreibung, kein Re-Training-Guide).

Hier ist dein neues `README.md`:

---

````markdown
# ğŸ§  Belkis LLM Finetunes

> **Eigene Fine-Tuning-Experimente mit [Unsloth](https://github.com/unslothai/unsloth) & LLaMA â€“ inklusive Trainingsskript, Multi-Adapter-Chat und Analyse-Tools.**

![Python](https://img.shields.io/badge/Python-3.12-blue?logo=python)
![Framework](https://img.shields.io/badge/Framework-PyTorch-red?logo=pytorch)
![Unsloth](https://img.shields.io/badge/Optimized_by-Unsloth-yellow)
![GPU](https://img.shields.io/badge/GPU-RTX3070-76B900?logo=nvidia)
![License](https://img.shields.io/badge/License-MIT-green)

---

## ğŸ§© ProjektÃ¼berblick

Dieses Repository enthÃ¤lt meine persÃ¶nlichen Experimente zum Fine-Tuning von LLaMA-Modellen mit **Unsloth**.  
Ziel war es, verschiedene DatensÃ¤tze wie **Dolly**, **HellaSwag** und **GQuad** zu kombinieren und eigene Adapter zu erzeugen, die unterschiedliche FÃ¤higkeiten (Instruction-, Reasoning- und Commonsense-Training) reprÃ¤sentieren.

Der Fokus liegt auf:
- ğŸš€ effizientem Training auf Consumer-GPUs (8 GB VRAM)
- ğŸ”„ systematischer Vergleich mehrerer Finetunes
- ğŸ’¬ lokal ausfÃ¼hrbare Chat-Skripte ohne Cloud-AbhÃ¤ngigkeit

---

## âš™ï¸ Installation & Setup

```bash
# Projekt klonen
git clone https://github.com/BEKO2210/belkis-llm-finetunes.git
cd belkis-llm-finetunes

# Virtuelle Umgebung (empfohlen)
python3 -m venv venv
source venv/bin/activate

# AbhÃ¤ngigkeiten installieren
pip install --upgrade pip
pip install -r requirements.txt
````

---

## ğŸ§  Training (SFT) mit Unsloth

Das Fine-Tuning erfolgte mit **Unsloth**, um LLaMA-Modelle durch Supervised Fine-Tuning (SFT) auf verschiedene Aufgaben anzupassen.

Beispielhafter Ablauf (symbolisch):

```bash
# Beispielhafte Trainingsaufrufe
DATASET=dolly python3 train_sft.py
DATASET=hellaswag python3 train_sft.py
DATASET=gquad_local python3 train_sft.py
```

Ergebnisse (Adapter & Tokenizer-Dateien) befinden sich in:

```
out_dolly/checkpoint-939/
out_gquad_local/checkpoint-720/
out_hellaswag/checkpoint-32/
```

Jeder Ordner enthÃ¤lt:

* `adapter_model.safetensors` â€“ das LoRA-Gewicht
* `tokenizer.json` + `config.json` â€“ Modelldefinition
* `training_args.bin` â€“ Trainingsparameter

> âš ï¸ Die genutzten DatensÃ¤tze und Basismodelle sind lizenzgebunden.
> Bitte deren Bedingungen beachten, falls das Setup reproduziert wird.

---

## ğŸ’¬ Nutzung der Chat-Skripte

### 1ï¸âƒ£ `chat_dolly.py` â€“ Einzel-Chat mit einem Adapter

Startet einen interaktiven Chat mit dem Dolly-Adapter:

```bash
python3 chat_dolly.py
```

Beispiel-Eingaben:

```
Wie funktionieren neuronale Netze?
ErklÃ¤re Deep Learning fÃ¼r ein Kind in 3 SÃ¤tzen.
```

---

### 2ï¸âƒ£ `chat_all.py` â€“ Multi-Adapter-Vergleich

Dieses Skript fÃ¼hrt denselben Prompt nacheinander auf mehreren Modellen aus
und zeigt die Antworten von:

* ğŸ§  DOLLY (Instruction)
* ğŸ§© GQUAD (Reasoning)
* ğŸ’¡ HELLASWAG (Commonsense)

```bash
python3 chat_all.py
```

Dadurch lassen sich **Antwortstil, Argumentationslogik und PrÃ¤zision** direkt vergleichen.

---

## ğŸ’» Hardware- & Framework-Setup

| Komponente        | Beschreibung                                      |
| ----------------- | ------------------------------------------------- |
| **GPU**           | NVIDIA GeForce RTX 3070 (8 GB VRAM)               |
| **OS**            | Linux (Ubuntu / Mint / WSL2)                      |
| **Frameworks**    | PyTorch â€¢ Unsloth â€¢ Transformers                  |
| **Optimierungen** | 4-Bit Loading, Quantized Adapters, Layer Patching |

Unsloth bietet native Performance-Boosts fÃ¼r LoRA-Training und Inference,
sodass auch auf kleinen GPUs effizient gearbeitet werden kann.

---

## ğŸ§­ Roadmap / Ideen

* ğŸ¤– **â€Belkis-v1â€œ â€“ gemeinsamer Adapter**, der mehrere DatensÃ¤tze kombiniert
* ğŸ“Š Automatisches **Evaluation-Script** mit Batch-Prompts
* ğŸ§© Export der Adapter zum Hugging Face Hub
* ğŸ—£ï¸ Verfeinertes **Prompt-Design** fÃ¼r saubere, deutschsprachige, fachlich prÃ¤zise Antworten

---

## âš–ï¸ Lizenz

Der Code in diesem Repository steht unter einer **MIT-Ã¤hnlichen Lizenz**.
Die verwendeten DatensÃ¤tze und Basismodelle unterliegen **eigenen Lizenzbedingungen**,
die bei jeglicher Nutzung oder Weiterverarbeitung beachtet werden mÃ¼ssen.

---

## ğŸ‘¤ Autor

**Belkis Aslani**
Lagerleitstand @ HWA AG â€¢ AI & Automation Enthusiast
ğŸ“ Freiberg am Neckar (Germany)
ğŸŒ [https://www.it-handwerk-stuttgart.de](https://www.it-handwerk-stuttgart.de)
ğŸ“« [belkis.aslani@gmail.de](mailto:belkis.aslani@gmail.de)

---

â­ Wenn dir dieses Projekt gefÃ¤llt, lass gern ein **Star** auf GitHub da!
