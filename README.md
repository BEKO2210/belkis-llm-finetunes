Perfekt ğŸ‘ Belkis â€” hier ist deine vollstÃ¤ndige **README.md**, komplett sauber aufgebaut und so formatiert,
dass **nur echter Code** in Codeboxen steht (bash, text, python etc.).
Alles andere ist FlieÃŸtext, damit GitHub es schÃ¶n rendert.

---

# ğŸ§  Belkis LLM Finetunes

> PersÃ¶nliche Fine-Tuning-Experimente mit **Unsloth** & **LLaMA** â€“ optimiert fÃ¼r Consumer-GPUs (RTX 3070 / 8 GB VRAM).

![Python](https://img.shields.io/badge/Python-3.12-blue)
![Framework](https://img.shields.io/badge/Framework-PyTorch-red)
![Unsloth](https://img.shields.io/badge/Optimized_by-Unsloth-yellow)
![GPU](https://img.shields.io/badge/GPU-RTX3070-76B900)
![License](https://img.shields.io/badge/License-MIT-green)

---

## ğŸš€ ProjektÃ¼berblick

Dieses Repository enthÃ¤lt meine persÃ¶nlichen Experimente zum **Fine-Tuning von LLaMA-Modellen mit Unsloth**.
Der Fokus liegt auf:

* **Effizientem Training** auf kleiner GPU
* **LoRA-Finetuning** mit unterschiedlichen DatensÃ¤tzen
* **Lokal ausfÃ¼hrbaren Chat-Skripten**
* **Vergleichsanalyse** zwischen mehreren Adaptern

| Ordner            | Datensatz | Schwerpunkt               |
| ----------------- | --------- | ------------------------- |
| `out_dolly`       | Dolly     | Instruction Following     |
| `out_gquad_local` | GQuad     | Reasoning                 |
| `out_hellaswag`   | HellaSwag | Commonsense Understanding |

Ziel: Ein leichtgewichtiges, lokales KI-Setup, das eigene Finetunes direkt testen und vergleichen kann.

---

## âš™ï¸ Installation & Setup

### Voraussetzungen

* Python 3.12
* CUDA-fÃ¤hige GPU (z. B. RTX 3070)
* Git installiert

### Projekt klonen und vorbereiten

```bash
git clone https://github.com/BEKO2210/belkis-llm-finetunes.git
cd belkis-llm-finetunes
```

### Virtuelle Umgebung (empfohlen)

```bash
python3 -m venv venv
source venv/bin/activate     # Linux/Mac
# venv\Scripts\activate      # Windows
```

### AbhÃ¤ngigkeiten installieren

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### Beispielinhalt der `requirements.txt`

```text
torch
transformers
unsloth
accelerate
safetensors
peft
```

---

## ğŸ§  Training (SFT) mit Unsloth

Das Fine-Tuning wurde mit **Unsloth** durchgefÃ¼hrt, um LLaMA-Modelle mittels **Supervised Fine-Tuning (SFT)** anzupassen.
Ziel ist es, aus verschiedenen DatensÃ¤tzen spezialisierte Adapter zu erzeugen.

### Beispielhafte Trainingsaufrufe

```bash
DATASET=dolly python3 train_sft.py
DATASET=hellaswag python3 train_sft.py
DATASET=gquad_local python3 train_sft.py
```

### Typische Ausgabestruktur

```text
out_dolly/
 â””â”€â”€ checkpoint-939/
      â”œâ”€â”€ adapter_model.safetensors
      â”œâ”€â”€ adapter_config.json
      â”œâ”€â”€ tokenizer.json
      â”œâ”€â”€ tokenizer_config.json
      â”œâ”€â”€ training_args.bin
      â””â”€â”€ README.md
```

> âš ï¸ Hinweis: Die verwendeten Basismodelle und DatensÃ¤tze sind lizenzabhÃ¤ngig.
> FÃ¼r Reproduktionen mÃ¼ssen deren Lizenzen separat beachtet werden.

---

## ğŸ’¬ Nutzung der Chat-Skripte

### 1ï¸âƒ£ `chat_dolly.py` â€“ Einzelchat mit dem Dolly-Adapter

Startet einen interaktiven Konsolenchat mit deinem trainierten Dolly-Adapter.

```bash
python3 chat_dolly.py
```

Beispiel:

```
=== Belkis Dolly-Chat ===
Du: ErklÃ¤re Deep Learning so, dass es ein Kind versteht.
LLM: Deep Learning ist wie ein Gehirn fÃ¼r Computer. Es lernt aus Beispielen, um Dinge zu erkennen.
```

---

### 2ï¸âƒ£ `chat_all.py` â€“ Vergleich mehrerer Adapter

Dieses Skript fÃ¼hrt denselben Prompt auf mehreren Modellen aus und zeigt die Antworten hintereinander.
Dadurch kann man direkt sehen, wie sich **Instruction-, Reasoning-** und **Commonsense-Adapter** unterscheiden.

```bash
python3 chat_all.py
```

Beispielausgabe:

```
ğŸ§  [DOLLY] Instruction Answer:
"Neuronale Netze sind Computermodelle, die wie Gehirne lernen."

ğŸ§© [GQUAD] Reasoning Answer:
"Ein neuronales Netz kombiniert viele kleine Berechnungen, um ZusammenhÃ¤nge zu erkennen."

ğŸ’¡ [HELLASWAG] Commonsense Answer:
"Neuronale Netze helfen Computern, Dinge wie Menschen zu verstehen â€“ z. B. Sprache oder Bilder."
```

---

## ğŸ’» Hardware & Frameworks

| Komponente        | Beschreibung                                                           |
| ----------------- | ---------------------------------------------------------------------- |
| **GPU**           | NVIDIA GeForce RTX 3070 (8 GB VRAM)                                    |
| **OS**            | Linux (Ubuntu / Mint / WSL2)                                           |
| **Frameworks**    | PyTorch 2.8 â€¢ Transformers 4.57 â€¢ Unsloth â€¢ Accelerate                 |
| **Optimierungen** | 4-Bit Loading â€¢ Gradient Checkpointing â€¢ LoRA Adapters â€¢ Fast Patching |

---

## ğŸ§­ Roadmap / Ideen

* ğŸ¤– Gemeinsamer Multi-Datensatz-Adapter (â€Belkis-v1â€œ)
* ğŸ“Š Automatisiertes Evaluations-Skript fÃ¼r Batch-Prompts
* ğŸ§© Export der LoRA-Adapter zu Hugging Face Hub
* ğŸ—£ï¸ Besseres Prompt-Design fÃ¼r prÃ¤gnante, deutsche Antworten

---

## âš–ï¸ Lizenz

Der Code in diesem Repository steht unter einer **MIT-Ã¤hnlichen Lizenz**.
Die verwendeten Basis-Modelle und DatensÃ¤tze haben **eigene Lizenzbedingungen**,
die bei Nutzung oder Weiterverarbeitung berÃ¼cksichtigt werden mÃ¼ssen.

---

## ğŸ‘¤ Autor

**Belkis Aslani**
Lagerleitstand @ HWA AG  â€¢  AI & Automation Enthusiast
ğŸ“ Freiberg am Neckar (Germany)
ğŸŒ [https://www.it-handwerk-stuttgart.de](https://www.it-handwerk-stuttgart.de)
ğŸ“« [belkis.aslani@gmail.de](mailto:belkis.aslani@gmail.de)

---

â­ Wenn dir dieses Projekt gefÃ¤llt, lass gern ein **Star** auf GitHub da!
